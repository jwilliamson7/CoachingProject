\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{bryson2024}
\citation{collins2007}
\citation{gilfix2020}
\babel@aux{USenglish}{}
\@writefile{toc}{\contentsline {author}{}{1}{Doc-Start}}
\@writefile{toc}{\contentsline {chapter}{Predicting NFL Head Coach Tenure Using Ordinal Classification}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{gilfix2020}
\citation{cannon2025}
\citation{lock2014}
\citation{david2011}
\citation{wolfson2011}
\citation{yurko2019}
\citation{roach2016}
\citation{mielke2007}
\citation{urschel2011}
\citation{chen2016}
\citation{pfr}
\citation{pedregosa2011}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data and Features}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 1}{\ignorespaces Feature categories and counts for the 150 engineered candidate features. Each coaching hire is characterized by core experience metrics, performance statistics from prior coordinator and head coaching roles, and the hiring team's recent performance.}}{3}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:feature_categories}{{1}{3}{Feature categories and counts for the 150 engineered candidate features. Each coaching hire is characterized by core experience metrics, performance statistics from prior coordinator and head coaching roles, and the hiring team's recent performance}{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Feature Normalization}{3}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{eq:zscore}{{1}{3}{Feature Normalization}{equation.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Missing Data Imputation}{3}{subsubsection.3.1.2}\protected@file@percent }
\citation{frank2001}
\citation{chen2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Ordinal Classification Model}{4}{subsection.3.2}\protected@file@percent }
\newlabel{eq:tenure_class}{{2}{4}{Ordinal Classification Model}{equation.2}{}}
\newlabel{eq:xgboost}{{6}{4}{Ordinal Classification Model}{equation.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation Methodology}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Metrics}{4}{subsubsection.3.3.1}\protected@file@percent }
\newlabel{eq:qwk}{{7}{4}{Metrics}{equation.7}{}}
\citation{lundberg2017unified}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Cross-Validation Strategy}{5}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Model Comparison}{5}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Feature Selection}{5}{subsection.3.4}\protected@file@percent }
\newlabel{sec:feature_selection}{{3.4}{5}{Feature Selection}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{6}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{6}{Results}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Feature Selection}{6}{subsection.4.1}\protected@file@percent }
\newlabel{sec:feature_selection_results}{{4.1}{6}{Feature Selection}{subsection.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 2}{\ignorespaces Model performance with SHAP-ranked feature subsets across 50 independent train/test splits. 95\% CI = confidence interval for the mean ($t$-distribution). Bold indicates peak QWK.}}{6}{table.caption.3}\protected@file@percent }
\newlabel{tab:parsimony}{{2}{6}{Model performance with SHAP-ranked feature subsets across 50 independent train/test splits. 95\% CI = confidence interval for the mean ($t$-distribution). Bold indicates peak QWK}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Ordinal Classification Model Performance}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison with Standard Multiclass Classification}{6}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {Fig. 1}{\ignorespaces Model performance as a function of feature count (SHAP-ranked). Shaded bands show $\pm $1 standard deviation across 50 independent train/test splits. Dashed red line indicates full-model (150 feature) performance. Performance peaks at 40 features and generally declines beyond 50 features.}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:parsimony}{{1}{7}{Model performance as a function of feature count (SHAP-ranked). Shaded bands show $\pm $1 standard deviation across 50 independent train/test splits. Dashed red line indicates full-model (150 feature) performance. Performance peaks at 40 features and generally declines beyond 50 features}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Feature Importance}{7}{subsection.4.4}\protected@file@percent }
\newlabel{sec:feature_importance}{{4.4}{7}{Feature Importance}{subsection.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 3}{\ignorespaces The 40 SHAP-selected features used in the final model, ranked by normalized importance (mean $|\text  {SHAP}|$ across 50 train/test partitions, normalized to sum to 1) with 95\% confidence intervals. Category abbreviations: HC Opp = HC Opponent Stats, HC = HC Team Stats, DC = DC Stats, Hire = Hiring Team, OC = OC Stats, Core = Core Experience.}}{8}{table.caption.5}\protected@file@percent }
\newlabel{tab:selected_features}{{3}{8}{The 40 SHAP-selected features used in the final model, ranked by normalized importance (mean $|\text {SHAP}|$ across 50 train/test partitions, normalized to sum to 1) with 95\% confidence intervals. Category abbreviations: HC Opp = HC Opponent Stats, HC = HC Team Stats, DC = DC Stats, Hire = Hiring Team, OC = OC Stats, Core = Core Experience}{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 4}{\ignorespaces Coach tenure classification prediction results (Ordinal Model, 40 features). Metrics are averaged across 50 independent train/test partitions; 95\% CI = confidence interval for the mean ($t$-distribution).}}{8}{table.caption.6}\protected@file@percent }
\newlabel{tab:tenure_results}{{4}{8}{Coach tenure classification prediction results (Ordinal Model, 40 features). Metrics are averaged across 50 independent train/test partitions; 95\% CI = confidence interval for the mean ($t$-distribution)}{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 5}{\ignorespaces Ordinal vs.\ Multiclass model comparison across 50 independent train/test partitions (40-feature model). Mean $\Delta $ = Ordinal $-$ Multiclass. 95\% CI = confidence interval for the mean difference (based on the $t$-distribution). $p$ = one-sided paired $t$-test.}}{8}{table.caption.8}\protected@file@percent }
\newlabel{tab:model_comparison}{{5}{8}{Ordinal vs.\ Multiclass model comparison across 50 independent train/test partitions (40-feature model). Mean $\Delta $ = Ordinal $-$ Multiclass. 95\% CI = confidence interval for the mean difference (based on the $t$-distribution). $p$ = one-sided paired $t$-test}{table.caption.8}{}}
\citation{roach2016}
\@writefile{lof}{\contentsline {figure}{\numberline {Fig. 2}{\ignorespaces Confusion matrix averaged across 50 independent train/test partitions. Each cell shows the proportion of instances with that true/predicted class combination, with the average raw count per partition in parentheses. Rows are normalized to sum to 1.0.}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:confusion_matrix}{{2}{9}{Confusion matrix averaged across 50 independent train/test partitions. Each cell shows the proportion of instances with that true/predicted class combination, with the average raw count per partition in parentheses. Rows are normalized to sum to 1.0}{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 6}{\ignorespaces Feature importance by category measured using mean absolute SHAP values across 50 train/test partitions. Total $|\text  {SHAP}|$ is the sum across all features in each category; Avg $|\text  {SHAP}|$ is the mean per feature. 95\% CI = confidence interval for the mean ($t$-distribution).}}{9}{table.caption.9}\protected@file@percent }
\newlabel{tab:shap_categories}{{6}{9}{Feature importance by category measured using mean absolute SHAP values across 50 train/test partitions. Total $|\text {SHAP}|$ is the sum across all features in each category; Avg $|\text {SHAP}|$ is the mean per feature. 95\% CI = confidence interval for the mean ($t$-distribution)}{table.caption.9}{}}
\bibcite{collins2007}{{1}{2007}{{Collins}}{{}}}
\bibcite{bryson2024}{{2}{2024}{{Bryson et al.}}{{}}}
\bibcite{cannon2025}{{3}{2025}{{Cannon et al.}}{{}}}
\bibcite{chen2016}{{4}{2016}{{Chen and Guestrin}}{{}}}
\bibcite{david2011}{{5}{2011}{{David et al.}}{{}}}
\bibcite{frank2001}{{6}{2001}{{Frank and Hall}}{{}}}
\bibcite{gilfix2020}{{7}{2020}{{Gilfix et al.}}{{}}}
\bibcite{lock2014}{{8}{2014}{{Lock and Nettleton}}{{}}}
\bibcite{lundberg2017unified}{{9}{2017}{{Lundberg and Lee}}{{}}}
\bibcite{mielke2007}{{10}{2007}{{Mielke}}{{}}}
\bibcite{pedregosa2011}{{11}{2011}{{Pedregosa et al.}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{10}{section.5}\protected@file@percent }
\bibcite{pfr}{{12}{2025}{{Pro-Football-Reference}}{{}}}
\bibcite{roach2016}{{13}{2016}{{Roach}}{{}}}
\bibcite{urschel2011}{{14}{2011}{{Urschel and Zhuang}}{{}}}
\bibcite{wolfson2011}{{15}{2011}{{Wolfson et al.}}{{}}}
\bibcite{yurko2019}{{16}{2019}{{Yurko et al.}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Feature Descriptions}{12}{appendix.A}\protected@file@percent }
\newlabel{app:features}{{A}{12}{Feature Descriptions}{appendix.A}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 7}{\ignorespaces Feature descriptions (Features 1--41)}}{12}{table.caption.11}\protected@file@percent }
\newlabel{tab:features_1}{{7}{12}{Feature descriptions (Features 1--41)}{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 8}{\ignorespaces Feature descriptions (Features 42--74)}}{13}{table.caption.12}\protected@file@percent }
\newlabel{tab:features_2}{{8}{13}{Feature descriptions (Features 42--74)}{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 9}{\ignorespaces Feature descriptions (Features 75--107)}}{14}{table.caption.13}\protected@file@percent }
\newlabel{tab:features_3}{{9}{14}{Feature descriptions (Features 75--107)}{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 10}{\ignorespaces Feature descriptions (Features 108--150)}}{15}{table.caption.14}\protected@file@percent }
\newlabel{tab:features_4}{{10}{15}{Feature descriptions (Features 108--150)}{table.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Data Distributions}{16}{appendix.B}\protected@file@percent }
\newlabel{app:distributions}{{B}{16}{Data Distributions}{appendix.B}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {Fig. 3}{\ignorespaces Coach tenure classification frequency distribution across all 635 coaching hire instances with known tenure outcomes. Class 0: short tenure (1--2 years, 49.0\%); Class 1: medium tenure (3--4 years, 26.8\%); Class 2: long tenure (5+ years, 24.3\%).}}{16}{figure.caption.15}\protected@file@percent }
\newlabel{fig:tenure_dist}{{3}{16}{Coach tenure classification frequency distribution across all 635 coaching hire instances with known tenure outcomes. Class 0: short tenure (1--2 years, 49.0\%); Class 1: medium tenure (3--4 years, 26.8\%); Class 2: long tenure (5+ years, 24.3\%)}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Partial Dependence Plots}{17}{appendix.C}\protected@file@percent }
\newlabel{app:partial_dependence}{{C}{17}{Partial Dependence Plots}{appendix.C}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {Fig. 4}{\ignorespaces Partial dependence plots for the six most predictive features. Each panel shows how the predicted probability of each tenure class changes as the feature value varies, with all other features held at their observed values. Feature values are normalized relative to league averages.}}{17}{figure.caption.16}\protected@file@percent }
\newlabel{fig:partial_dependence}{{4}{17}{Partial dependence plots for the six most predictive features. Each panel shows how the predicted probability of each tenure class changes as the feature value varies, with all other features held at their observed values. Feature values are normalized relative to league averages}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Model Hyperparameters}{18}{appendix.D}\protected@file@percent }
\newlabel{app:hyperparameters}{{D}{18}{Model Hyperparameters}{appendix.D}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 11}{\ignorespaces Hyperparameter search space for randomized search (1{,}000 iterations, 5-fold coach-level CV, scored by QWK). Values are sampled uniformly from each discrete set.}}{18}{table.caption.17}\protected@file@percent }
\newlabel{tab:search_space}{{11}{18}{Hyperparameter search space for randomized search (1{,}000 iterations, 5-fold coach-level CV, scored by QWK). Values are sampled uniformly from each discrete set}{table.caption.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {Tab. 12}{\ignorespaces Final hyperparameters for the ordinal XGBoost classifier model (QWK-optimized)}}{18}{table.caption.18}\protected@file@percent }
\newlabel{tab:classifier_hyperparams}{{12}{18}{Final hyperparameters for the ordinal XGBoost classifier model (QWK-optimized)}{table.caption.18}{}}
\newlabel{LastPage}{{D}{18}{Model Hyperparameters}{page.18}{}}
\gdef\lastpage@lastpage{18}
\gdef\lastpage@lastpageHy{18}
\gdef \@abspage@last{18}
